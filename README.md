# BTLbigdata-group30 - University Learning Analytics System

Lambda Architecture implementation for student learning analytics with Kafka, Spark, and MinIO.

---

## ğŸ“ Project Structure (Reorganized)

```
BTLbigdata-group30/
â”œâ”€â”€ ingestion_layer/                # Kafka â†’ Storage Ingestion
â”‚   â”œâ”€â”€ producer.py                # Event generator (6 categories)
â”‚   â”œâ”€â”€ ingest_layer.py           # Kafka â†’ HDFS ingestion (local)
â”‚   â”œâ”€â”€ minio_ingest.py           # Kafka â†’ MinIO ingestion
â”‚   â”œâ”€â”€ minio_ingest_k8s.py       # Kafka â†’ MinIO (Kubernetes)
â”‚   â”œâ”€â”€ Dockerfile.ingestion       # Docker image for ingestion
â”‚   â””â”€â”€ README.md                  # Ingestion layer documentation
â”‚
â”œâ”€â”€ batch_layer/                    # Batch Processing Layer âœ…
â”‚   â”œâ”€â”€ jobs/                      # PySpark batch jobs (5 jobs)
â”‚   â”‚   â”œâ”€â”€ auth_batch_job.py     # Authentication analytics
â”‚   â”‚   â”œâ”€â”€ assessment_batch_job.py    # Assessment analytics
â”‚   â”‚   â”œâ”€â”€ video_batch_job.py    # Video engagement analytics
â”‚   â”‚   â”œâ”€â”€ course_batch_job.py   # Course interaction analytics
â”‚   â”‚   â””â”€â”€ profile_notification_batch_job.py
â”‚   â”œâ”€â”€ oozie/                     # Oozie orchestration
â”‚   â”‚   â”œâ”€â”€ workflow.xml          # Parallel job workflow
â”‚   â”‚   â”œâ”€â”€ coordinator.xml       # Daily scheduler
â”‚   â”‚   â””â”€â”€ job.properties        # Oozie configuration
â”‚   â”œâ”€â”€ config.py                  # Centralized config
â”‚   â”œâ”€â”€ run_batch_jobs.py         # Manual runner
â”‚   â”œâ”€â”€ deploy_oozie.sh/.ps1      # Deployment scripts
â”‚   â”œâ”€â”€ README.md                  # Complete documentation
â”‚   â”œâ”€â”€ QUICKSTART.md              # Quick start guide
â”‚   â””â”€â”€ IMPLEMENTATION_SUMMARY.md  # Implementation summary
â”‚
â”œâ”€â”€ speed_layer/                    # Real-Time Stream Processing â³
â”‚   â”œâ”€â”€ stream_layer.py           # Real-time processor (TBD)
â”‚   â””â”€â”€ README.md                  # Speed layer documentation
â”‚
â”œâ”€â”€ serving_layer/                  # Unified Query Interface â³
â”‚   â”œâ”€â”€ serving_layer.py          # Query service (TBD)
â”‚   â””â”€â”€ README.md                  # Serving layer documentation
â”‚
â”œâ”€â”€ kafka/                          # Kafka Kubernetes configs
â”‚   â”œâ”€â”€ deployment.yaml            # Kafka cluster (3 nodes)
â”‚   â”œâ”€â”€ topics.yaml                # Topic definitions (6 topics)
â”‚   â”œâ”€â”€ storage-class.yaml         # Storage configuration
â”‚   â”œâ”€â”€ persistent-volumn.yaml     # Multi-node PVs
â”‚   â””â”€â”€ persistent-volumn-minikube.yaml
â”‚
â”œâ”€â”€ minio/                          # MinIO deployment
â”‚   â””â”€â”€ deployment.yaml            # S3-compatible storage
â”‚
â”œâ”€â”€ spark/                          # Spark jobs
â”‚   â””â”€â”€ ingestion-job.yaml         # Ingestion K8s job
â”‚
â”œâ”€â”€ deployment/                     # Deployment scripts & guides
â”‚   â”œâ”€â”€ deploy_minikube.ps1       # Auto-deploy to Minikube
â”‚   â”œâ”€â”€ cleanup_minikube.ps1      # Cleanup Minikube
â”‚   â”œâ”€â”€ MINIKUBE_TESTING_GUIDE.md # Complete testing guide
â”‚   â”œâ”€â”€ MINIKUBE_QUICK_REFERENCE.md
â”‚   â”œâ”€â”€ TESTING_COMPARISON.md     # Local vs Minikube
â”‚   â””â”€â”€ TESTING_WORKFLOW.md       # Testing workflows
â”‚
â”œâ”€â”€ config/                         # Configuration files
â”‚   â”œâ”€â”€ docker-compose.yml         # Local development setup
â”‚   â”œâ”€â”€ hadoop.env                 # Hadoop configuration
â”‚   â””â”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ event-schema-specification.md  # Event schemas
â”‚   â”œâ”€â”€ architecture-design.md     # System architecture
â”‚   â”œâ”€â”€ problem-definition.md      # Project requirements
â”‚   â””â”€â”€ deployment-guide.md        # Setup instructions
â”‚
â”œâ”€â”€ batch_layer.py                  # DEPRECATED (moved to batch_layer/)
â”œâ”€â”€ generate_fake_data.ipynb       # Data generation notebook
â””â”€â”€ README.md                       # This file
```

---

## ğŸ—ï¸ Lambda Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA SOURCES                                â”‚
â”‚            (Student Learning Events - 6 Categories)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INGESTION LAYER (Kafka)                        â”‚
â”‚  Producer â†’ Kafka Topics â†’ MinIO (Raw Events)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BATCH LAYER âœ…       â”‚        â”‚   SPEED LAYER â³              â”‚
â”‚   (Historical Data)    â”‚        â”‚   (Real-Time Data)            â”‚
â”‚                        â”‚        â”‚                               â”‚
â”‚ â€¢ Oozie Scheduler      â”‚        â”‚ â€¢ Spark Streaming             â”‚
â”‚ â€¢ 5 PySpark Jobs       â”‚        â”‚ â€¢ Windowed Aggregations       â”‚
â”‚ â€¢ 37 Batch Views       â”‚        â”‚ â€¢ Incremental Updates         â”‚
â”‚ â€¢ Daily Processing     â”‚        â”‚ â€¢ Low Latency (seconds)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     SERVING LAYER â³             â”‚
         â”‚  (Unified Query Interface)       â”‚
         â”‚                                  â”‚
         â”‚  Batch Views + Speed Views       â”‚
         â”‚  REST API / Query Service        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Legend**:
- âœ… **Complete** - Fully implemented and tested
- â³ **Planned** - Next implementation phase

---

## ğŸ¯ Implementation Status

| Layer | Status | Components | Batch Views |
|-------|--------|------------|-------------|
| **Ingestion** | âœ… Complete | 4 scripts, 6 Kafka topics | - |
| **Batch Layer** | âœ… Complete | 5 PySpark jobs, Oozie orchestration | 37 views |
| **Speed Layer** | â³ Planned | Real-time stream processing | TBD |
| **Serving Layer** | â³ Planned | Query API, view merger | TBD |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8-3.11
- Docker Desktop
- Apache Spark 3.5.0
- Kafka (via Docker Compose or Minikube)
- MinIO (via Docker Compose or Minikube)

### Option 1: Local Development (Docker Compose)

1. **Start infrastructure**:
```powershell
cd config
docker-compose up -d
```

2. **Generate events**:
```powershell
python ingestion_layer/producer.py
```

3. **Ingest to MinIO**:
```powershell
python ingestion_layer/minio_ingest.py
```

4. **Run batch processing**:
```powershell
python batch_layer/run_batch_jobs.py s3a://bucket-0/master_dataset s3a://bucket-0/batch_views
```

### Option 2: Minikube (Kubernetes)

1. **Deploy to Minikube**:
```powershell
cd deployment
.\deploy_minikube.ps1
```

2. **Port forward services**:
```powershell
# Terminal 1: Kafka
kubectl port-forward service/kafka-cluster-kafka-bootstrap 9092:9092 -n kafka

# Terminal 2: MinIO
kubectl port-forward service/minio 9000:9000 -n minio
```

3. **Run ingestion**:
```powershell
python ingestion_layer/producer.py
python ingestion_layer/minio_ingest_k8s.py
```

4. **Deploy Oozie batch jobs**:
```powershell
cd batch_layer
.\deploy_oozie.ps1
oozie job -oozie http://localhost:11000/oozie -config oozie/job.properties -run
```

**ğŸ“š Detailed Guides**:
- [Ingestion Layer README](ingestion_layer/README.md)
- [Batch Layer README](batch_layer/README.md)
- [Batch Layer Quick Start](batch_layer/QUICKSTART.md)
- [Minikube Testing Guide](deployment/MINIKUBE_TESTING_GUIDE.md)

---

## ğŸ“Š Event Schema

The system captures **6 event categories** with **30+ event types**:

1. **Authentication** (`auth_topic`) - Login, Logout, Signup
2. **Assessment** (`assessment_topic`) - Assignments, Quizzes, Grading
3. **Video** (`video_topic`) - Video watching behavior
4. **Course** (`course_topic`) - Enrollments, Materials, Downloads
5. **Profile** (`profile_topic`) - Profile updates, Avatar changes
6. **Notification** (`notification_topic`) - Notification delivery & engagement

**Complete specification**: [docs/event-schema-specification.md](docs/event-schema-specification.md)

---

## ğŸ”§ Configuration

### MinIO Configuration
- **Endpoint**: `http://minio:9000`
- **Console**: `http://localhost:9001`
- **Credentials**: `minioadmin / minioadmin`

### Kafka Configuration
- **Bootstrap Server**: `localhost:9092`
- **Topics**: 6 topics (auth, assessment, video, course, profile, notification)

### Spark Configuration
- **Executor Memory**: 4GB
- **Executor Cores**: 2
- **Executors**: 3

Edit configurations in:
- `config/docker-compose.yml` - Local development
- `batch_layer/config.py` - Batch processing
- `batch_layer/oozie/job.properties` - Oozie jobs

---

## ğŸ“¦ Batch Views (37 Total)

### Authentication (5 views)
- Daily active users (DAU)
- Hourly login patterns
- User session metrics
- Activity summary
- Registration analytics

### Assessment (7 views)
- Student submissions
- Engagement timeline
- Quiz performance
- Grading statistics
- Teacher workload
- Submission distribution
- Overall performance

### Video (7 views)
- Total watch time
- Student engagement
- Video popularity
- Daily engagement
- Course metrics
- Student-course summary
- Drop-off indicators

### Course (8 views)
- Enrollment stats
- Material access patterns
- Material popularity
- Download analytics
- Resource download stats
- Activity summary
- Daily engagement
- Overall metrics

### Profile & Notification (10 views)
- Profile update frequency
- Field changes
- Avatar changes
- Profile activity
- Notification delivery stats
- Engagement metrics
- Click-through rates
- User preferences
- Daily activity
- User summary

**Full documentation**: [batch_layer/README.md](batch_layer/README.md)

---

## ğŸ§ª Testing

### Test Ingestion Layer
```powershell
# Start infrastructure
cd config
docker-compose up -d

# Run producer and ingestion
python ingestion_layer/producer.py
python ingestion_layer/minio_ingest.py

# Verify in MinIO Console: http://localhost:9001
```

### Test Batch Layer
```powershell
# Run all batch jobs
python batch_layer/run_batch_jobs.py s3a://bucket-0/master_dataset s3a://bucket-0/batch_views

# Run specific job
python batch_layer/run_batch_jobs.py video s3a://bucket-0/master_dataset s3a://bucket-0/batch_views
```

### Test on Minikube
```powershell
cd deployment
.\deploy_minikube.ps1

# Follow prompts for testing
```

**Testing Guides**:
- [MINIKUBE_TESTING_GUIDE.md](deployment/MINIKUBE_TESTING_GUIDE.md)
- [TESTING_COMPARISON.md](deployment/TESTING_COMPARISON.md)

---

## ğŸ“– Documentation

- **[Architecture Design](docs/architecture-design.md)** - System architecture overview
- **[Event Schema](docs/event-schema-specification.md)** - Complete event definitions
- **[Problem Definition](docs/problem-definition.md)** - Project requirements
- **[Deployment Guide](docs/deployment-guide.md)** - Setup instructions

**Layer Documentation**:
- [Ingestion Layer](ingestion_layer/README.md)
- [Batch Layer](batch_layer/README.md) + [Quick Start](batch_layer/QUICKSTART.md)
- [Speed Layer](speed_layer/README.md)
- [Serving Layer](serving_layer/README.md)

---

## ğŸ› ï¸ Development Workflow

### Adding New Event Types

1. Update schema: `docs/event-schema-specification.md`
2. Update producer: `ingestion_layer/producer.py`
3. Create/update batch job: `batch_layer/jobs/<category>_batch_job.py`
4. Test ingestion â†’ batch processing

### Adding New Batch Views

1. Create computation function in relevant batch job
2. Write output to MinIO: `s3a://bucket-0/batch_views/<view_name>`
3. Document in batch job docstring
4. Update `batch_layer/config.py` batch_views list

### Deploying Changes

**Local**:
```powershell
# Restart affected services
docker-compose restart kafka minio

# Re-run jobs
python batch_layer/run_batch_jobs.py ...
```

**Oozie**:
```powershell
cd batch_layer
.\deploy_oozie.ps1
oozie job -kill <old-coordinator-id>
oozie job -run -config oozie/job.properties
```

---

## ğŸ” Monitoring

### MinIO Console
- URL: http://localhost:9001
- Credentials: `minioadmin / minioadmin`
- Browse: `bucket-0/master_dataset/` and `bucket-0/batch_views/`

### Spark UI
- URL: http://localhost:4040 (during job execution)
- Monitor: Job progress, stages, tasks

### Oozie UI
- URL: http://localhost:11000/oozie
- Monitor: Workflow status, coordinator jobs

---

## ğŸš§ Roadmap

### Phase 1: Ingestion & Batch âœ… (Complete)
- [x] Kafka event ingestion
- [x] MinIO storage
- [x] Batch layer with 5 PySpark jobs
- [x] 37 batch views
- [x] Oozie orchestration

### Phase 2: Speed Layer â³ (Next)
- [ ] Real-time stream processing
- [ ] Incremental view updates
- [ ] Windowed aggregations
- [ ] Late data handling

### Phase 3: Serving Layer â³
- [ ] Unified query interface
- [ ] Batch + speed view merger
- [ ] REST API
- [ ] Query optimization

### Phase 4: Production Readiness
- [ ] Monitoring dashboards (Grafana)
- [ ] Alerting system
- [ ] Performance optimization
- [ ] Scalability testing

---

## ğŸ‘¥ Team - Group 30

**Ingestion Layer Team**: Thá»‹nh, PhÃº, Tiáº¿n  
**Batch Ingestion Team**: LÃ¢m, Lá»™c

---

## ğŸ“„ License

University Big Data Course Project - 2025

---

## ğŸ†˜ Troubleshooting

### Common Issues

**Problem**: Cannot connect to Kafka  
**Solution**: Ensure Kafka is running: `docker ps | grep kafka` or check Minikube deployment

**Problem**: MinIO access denied  
**Solution**: Check credentials in config files (`minioadmin/minioadmin`)

**Problem**: Batch jobs fail with OOM  
**Solution**: Increase executor memory in `batch_layer/config.py`

**Problem**: No data in MinIO  
**Solution**: Ensure producer and ingestion are running, check Kafka topics have data

**More help**: Check respective README files in each layer directory

---

## ğŸ“ Support

- Check layer-specific README files
- Review documentation in `docs/`
- Inspect logs: `docker logs <container>` or `oozie job -log <job-id>`
- Verify data: MinIO Console or `mc ls minio/bucket-0/`

---

**Project Status**: Batch Layer Complete âœ… | Speed Layer In Progress â³
